---
title: "MD1"
author: "Pēteris Račinskis pr20015"
date: "4/7/2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. mājas darbs Mate6029

## 1. uzdevums

### a) Varbūtību telpas

Bibliotēka darbam ar varbūtību telpām:

``` {r, results = FALSE, message=FALSE}
library(prob)
```
2 kauliņa metienu modelēšana ar varbūtību telpu

``` {r}
roll2 = iidspace(c(1:6), ntrials=2, probs=rep(1/6, times=6))
A = subset(roll2, X1 == X2)
B = subset(roll2, X1+X2 >= 7 & X1+X2 <= 10)
C = subset(roll2, X1+X2 == 2 | X1+X2 == 7 | X1+X2 == 8)
test1 = subset(roll2, X1 == 1)
test2 = subset(roll2, X2 == 2)
```

Notikumu varbūtības:

``` {r}
Prob(A)
Prob(B)
Prob(C)
```

Notikumu šķēlums un varbūtību reizinājums:

``` {r}
(Prob(intersect(A,B,C)) == Prob(A) * Prob(B) * Prob(C))
```

Neatkarības pārbaudes: A un B; B un C:

``` {r}
(Prob(intersect(A,B)) == Prob(A) * Prob(B))
(Prob(intersect(B,C)) == Prob(B) * Prob(C))
```

3 kauliņa metienu modelēšana:

``` {r}
roll3 = iidspace(c(1:6), ntrials=3, probs=rep(1/6, times=6))
```

Notikumi - 3 dažādi skaitļi un visi vieninieki:

``` {r}
A = subset(roll3, !((X1 == X2) | (X1 == X3) | (X2 == X3)))
B = subset(roll3, X1 == 1 | X2 == 1 | X3 == 1)
```

Nosacītā varbūtība:

``` {r}
Prob(B, given = A)
```


### b) Diskrēti gadījuma lielumi

Palīgfunkciju definīcija (koda pārskatāmības nolūkos):

``` {r}
dist_mean <- function(dist) {
  sum(dist[1,]*dist[2,])
}
dist_var <- function(dist) {
  mu <- dist_mean(dist) 
  sum((dist[1,]^2)*dist[2,])-mu^2
}
dist_sigma <- function(dist) {
  sqrt(dist_var(dist))
}
interval_prob <- function(dist, a, b) {
  sum(dist[2, dist[1,] > a & dist[1,] < b])
}
single_prob <- function(dist, x) {
  dist[2, dist[1,] == x]
}
```

Apvienota funkcija, kas izpilda uzdevuma nosacījumus:

``` {r}
combined <- function(dist, x, a, b) {
  plot(dist[1,], dist[2,], type="b",xlab="x",ylab="P(X=x)")
  flatline <- rep(single_prob(dist,x),times=length(dist[1,]))
  lines(dist[1,],flatline)
  list(mu=dist_mean(dist),
       var=dist_var(dist),
       sig=dist_sigma(dist),
       interval=interval_prob(dist,a,b))
}
```

Pielietojums kauliņa metienam un binomiālajam sadalījumam:

``` {r}
d <- t(rolldie(1,makespace = TRUE))
n <- 10   
k <- 0:n  
p <- 0.5  
b <- rbind(k,dbinom(k,n,p))
par(mfrow = c(1,2))
r1 <- combined(d, 4, 1, 3)
r2 <- combined(b, 3, 2, 7)
``` 
```{r, echo=FALSE}
par(mfrow = c(1,1))
```

Kauliņa sadalījums:

``` {r}
r1
```

Binomiālais sadalījums:

``` {r}
r2
```

\newpage

## 2. uzdevums

Iterācijas funkcija:

``` {r}
nsize_repeat <- function(nsizes, params, times) {
  sapply(nsizes, function(i) {
    params$n <- i
    sapply(1:times, function(j) mean(params$cb(params)))
  })
}
```

Izlasi veidojošās funkcijas:

``` {r}
chi_callback <- function(params) {
  rchisq(params$n, params$df)
}
exp_callback <- function(params) {
  rexp(params$n, params$rate)
}
uni_callback <- function(params) {
  runif(params$n, params$min, params$max)
}
lnm_callback <- function(params) {
  rlnorm(params$n, params$meanlog, params$sdlog)
}
```

Izlašu konfigurācijas:

``` {r}
config = list(
  chi=list(cb=chi_callback,df=1),
  exp=list(cb=exp_callback,rate=1),
  uni=list(cb=uni_callback,min=-1,max=1),
  lnm=list(cb=lnm_callback,meanlog=1,sdlog=1)
)
```

Izlašu veidošana:

``` {r}
nsizes = c(2,10,50)
times = 1000
results <- lapply(config, function(i) nsize_repeat(nsizes, i, times))
```

Grafiku zīmēšanas funkcija un reizinātāji:

``` {r}
compare <- function(arg, data, mu, var, nvals, name) {
  par(mfrow = c(length(nvals),1))
  sapply(1:length(nvals), function(i) {
    y <- dnorm(arg, mu, sqrt(var*nvals[i]))
    hist(data[,i],freq=FALSE,breaks=50,main=paste(name,1/nvals[i]))
    lines(arg,y,col="red")
  })
  par(mfrow = c(1,1))
}

ns <- c(1/2, 1/10, 1/50)
```

\newpage
Chi-square grafiki:

``` {r, fig.height=8, results=FALSE}
xax <- seq(0,3,0.01)
compare(xax,results$chi,1,2,ns,"Chi square n = ")
```

\newpage
Exp grafiki:

``` {r, fig.height=8, results=FALSE}
compare(xax,results$exp,1,1,ns,"Exponential n = ")
```

\newpage
Uniform grafiki:

``` {r, fig.height=8, results=FALSE}
xax <- seq(-1,1,0.01)
compare(xax,results$uni,0,1/3,ns,"Uni n = ")
```

\newpage
Lognorm grafiki:

``` {r, fig.height=8, results=FALSE}
lnm_mean <- exp(1+1/2)
lnm_var <- (exp(1) - 1) * exp(3)
xax <- seq(0,20,0.01)
compare(xax,results$lnm,lnm_mean,lnm_var,ns,"Lnorm n = ")
```

\newpage
Pārrēķinātie rezultāti pie n = 100 un atbilstošie grafiki:

``` {r, fig.height=4, results=FALSE}
nsizes <- c(100)
ns <- c(1/100)
times <- 1000
new_data <- lapply(config, function(i) nsize_repeat(nsizes, i, times))
xax <- seq(0,3,0.01)
compare(xax,new_data$chi,1,2,ns,"Chi square n = ")
```
``` {r, fig.height=4}
compare(xax,new_data$exp,1,1,ns,"Exponential n = ")
```
\newpage
``` {r, fig.height=4}
xax <- seq(-1,1,0.01)
compare(xax,new_data$uni,0,1/3,ns,"Uni n = ")
```
``` {r, fig.height=4}
xax <- seq(0,10,0.01)
compare(xax,new_data$lnm,lnm_mean,lnm_var,ns,"Lnorm n = ")
```

Secinājumi: ar izlases izmēru n = 100 pietiek, lai redzētu konverģenci pie visiem sadalījumiem.

\newpage

## 3. uzdevums

### a) Datu kopa "quakes", apraksts

Datu kopas vispārīgs apraksts:

``` {r}
summary(quakes)
````

Satur mainīgos:

- lat,long: ģeogrāfiskās koordinātes

- depth(km): zemestrīces fokusa dziļums 

- mag: magnitūda

- stations: notikumu reģistrējušo novērošanas staciju skaits

### b) Kastu grafiki

``` {r}
attach(quakes)
par(mfrow = c(1,2))
boxplot(lat,main="lat")
boxplot(long,main="long")
par(mfrow = c(1,3))
boxplot(depth,main="depth")
boxplot(mag,main="mag")
boxplot(stations,main="stations")
```

``` {r, echo=FALSE}
par(mfrow = c(1,1))
```

Asimetriski sadalījumi:

- lat, long: it kā liels skaits izlēcēju un nobīde, taču jāņem vērā, ka koordinātes ir mākslīgi "nogrieztas", jo ņemtas no kuba formas telpas;

- mag, stations: diezgan skaidri redzami exponenciāli vai log-normāli sadalījumi;

- depth: grūti spriest, taču manāma asimetrija boxplot.

Ko nozīmē liels skaits izlēcēju: sadalījums ar "treknām astēm" un/vai izteiktu asimetriju - pēc noklusējuma "whisker" garumu nosaka kā 1.5 * (Q3-Q1), t.i., pusotru reizi "kastes" platuma.

### c) InsectSprays

Bibliotēka aprakstošo statistiku iegūšanai:

``` {r, results = FALSE, message = FALSE}
library(psych)

require(ggplot2)
require(qqplotr)
require(gridExtra)
```

Vispārīgi: kukaiņu skaiti eksperimentos ar dažādiem pesticīdiem.

``` {r}
summary(InsectSprays)
attach(InsectSprays)
```

Kastu grafiks un aprakstošās statistikas:

``` {r}
boxplot(count~spray)
describe(count)
describe(count[spray=="A"])
describe(count[spray=="B"])
describe(count[spray=="C"])
describe(count[spray=="D"])
describe(count[spray=="E"])
describe(count[spray=="F"])
```

Līdzīgās izlases:

- A,B,F

- D,E

Histogrammu zīmēšanas funkcija:

``` {r}
draw_near <- function(data, name) {
  h <- hist(data,prob=T,main = name)
  xax <- seq(min(h$breaks),max(h$breaks),0.01)
  lines(xax,dnorm(xax,mean(data),sd(data)),col="red",lwd=2)
}
```

\newpage
Histogrammas:

``` {r, echo=FALSE}
par(mfrow = c(1,2))
draw_near(count[spray=="A"], "Spray A")
draw_near(count[spray=="B"], "Spray B")
par(mfrow = c(1,1))
```

``` {r, echo=FALSE}
par(mfrow = c(1,2))
draw_near(count[spray=="C"], "Spray C")
draw_near(count[spray=="D"], "Spray D")
par(mfrow = c(1,1))
```

``` {r, echo=FALSE}
par(mfrow = c(1,2))
draw_near(count[spray=="E"], "Spray E")
draw_near(count[spray=="F"], "Spray F")
par(mfrow = c(1,1))
```


Funkcijas QQ,PP grafiku zīmēšanai (+- copy&paste no kursa materiāliem):

``` {r}

plot_PP_norm <- function(data) {
  g <- ggplot(data = data, mapping = aes(sample = count)) +
    stat_pp_band() +
    stat_pp_line() +
    stat_pp_point()+
    labs(title = paste("P-P plot",data$spray[1]), x = "Theoretical", y = "Sample")
  g
}
plot_QQ_norm <- function(data) {
  g <- ggplot(data = data, mapping = aes(sample = count)) +
    stat_qq_band() +
    stat_qq_line() +
    stat_qq_point()+
    labs(title = paste("Q-Q plot",data$spray[1]), x = "Theoretical", y = "Sample")
  g
}
plots <- function(data) {
  grid.arrange(plot_PP_norm(data),plot_QQ_norm(data),ncol=2)
}
compare_QQ <- function(d1,d2){
  x <- d1$count
  y <- d2$count
  sx <- sort(x)
  sy <- sort(y)
  lenx <- length(sx)
  leny <- length(sy)
  if (leny < lenx) sx <- approx(1L:lenx, sx, n = leny)$y
  if (leny > lenx) sy <- approx(1L:leny, sy, n = lenx)$y
  require(ggplot2)
  g = ggplot() + geom_point(aes(x=sx, y=sy))+
    geom_abline(intercept =0, slope = 1)+
    labs(title="QQ compare",x=d1$spray[1],y=d2$spray[1])
  g
}
compare_PP <- function(d1,d2,min_c,max_c) {
  x <- d1$count
  y <- d2$count
  fn1<-ecdf(x)
  fn2<-ecdf(y)
  xx<-seq(min_c,max_c,0.1)
  dd<-data.frame(y=fn1(xx),x=fn2(xx))
  g <- ggplot(dd, aes(x=x,y=y))+geom_point()+
    geom_abline(intercept =0, slope = 1)+
    labs(title="PP compare",x=d1$spray[1],y=d2$spray[1])
  g
}
compare_two <- function(d1,d2,min_c,max_c) {
  #par(mfrow = c(2,1))
  grid.arrange(compare_PP(d1,d2,min_c,max_c),compare_QQ(d1,d2),ncol=2)
  #par(mfrow = c(1,1))
}
```

Grafiki:

``` {r, echo=FALSE}
a <- subset(InsectSprays,spray=="A")
b <- subset(InsectSprays,spray=="B")
c <- subset(InsectSprays,spray=="C")
d <- subset(InsectSprays,spray=="D")
e <- subset(InsectSprays,spray=="E")
f <- subset(InsectSprays,spray=="F")
plots(a)
plots(b)
plots(c)
plots(d)
plots(e)
plots(f)
MIN <- min(InsectSprays$count)
MAX <- max(InsectSprays$count)
compare_two(a,b,MIN,MAX)
compare_two(a,f,MIN,MAX)
compare_two(b,f,MIN,MAX)
compare_two(c,d,MIN,MAX)
compare_two(c,e,MIN,MAX)
compare_two(d,e,MIN,MAX)
```

Secinājumi: 

- Pēc QQ/PP gandrīz visas izlases varētu būt normali sadalītas, taču histogrammās tikai  A un varbūt B izskatās pēc normālā sadalījuma.

- A,B,F ir diezgan līdzīgas, D,E - mazāk. Grūti spriest, vai kādas no izlasēm ņemtas no tā paša sadalījuma.

\newpage

## 4. uzdevums

Bibliotēka MLE optimizācijas uzdevumu risināšanai:

``` {r, results = FALSE, message = FALSE}
library(maxLik)
```

Momentu metode:

``` {r}
lnorm_pdf <-function(x,mu,sigma)
{
  location <- log(mu^2 / sqrt(sigma^2 + mu^2))
  shape <- sqrt(log(1 + (sigma^2 / mu^2)))
  dlnorm(x,location,shape)
}
# moment method for exp <- rate = 1/mean <-> mean = 1/rate
exp_pdf <- function(x,mu) {
  dexp(x,1/mu)
}
```

Maksimālās ticamības metode:

``` {r}
llf_lnorm <- function(param) {
  mu <- param[1]
  sd <- param[2]
  x <- stations
  llValue <- dlnorm(x, mean=mu, sd=sd, log=TRUE) 
  sum(llValue)
}
llf_exp <- function(param) {
  lambda <- param[1]
  x <- stations
  n <- length(x)
  n*log(lambda)-lambda*sum(x)
}

mu_init = 3.5
sd_init = 0.6
mllnm <- maxLik(llf_lnorm, start=c(mu_init,sd_init))
lambda_init <- 1/20
mlexp <- maxLik(llf_exp, start=c(lambda_init))

```

Salīdzinājuma grafiki:

``` {r, fig.height=4, message=FALSE}
attach(quakes)
hist(stations,prob=T,main="MME for exp and lnorm")
xax <- seq(0,max(stations),0.1)
x <- stations
lines(xax,lnorm_pdf(xax,mean(x),sd(x)),col="red",lwd=2)
lines(xax,exp_pdf(xax,mean(x)),col="blue",lwd=2)
```

``` {r, fig.height=4}
hist(stations,prob=T,main="MLE for lnorm and exp")
lines(xax,dlnorm(xax,mllnm$estimate[1],mllnm$estimate[2]),col="red",lwd=2)
lines(xax,dexp(xax,mlexp$estimate[1]),col="blue",lwd=2)
````

Eksponenciālais sadalījums izskatās tuvāks izlases formai.

Log-normālais sadalījums, šķiet, tuvāk atbilst datiem.

\newpage

## 5. uzdevums

Datu nolasīšana no faila (iepriekš sagatavota, apstrādājot copy-paste datus ar Python skriptu)

``` {r, message=FALSE}
df <- read.csv("anorex.csv")[,2:4]
attach(df)
```


### a) Datu apraksts

Dati doti tabulas formā ar 3 saistītām ("paired") kolonnām:

- A - Svars pirms terapijas;

- B - Svars pēc terapijas;

- C - Starpība.

Lai ar datiem pierādītu metodes efektivitāti, mean(A) < mean(B) un mean(C) > 0

### b) Kāpēc nulles hipotēze ir svarīga?

Nulles hipotēze ietver sākotnējo pieņēmumu par rezultātu (šai gadījumā - metode svaru neietekme), un kalpo kā atskaites punkts, pret ko salīdzināt iegūtos datus. Uzdodot problēmu nulles hipotēzes noraidīšanas formā var iepriekš noteikt kādu konkrētu pārliecības slieksni, pēc kā izdara secinājumus par eksperimenta rezultātiem un to nozīmi.

### c) t-testa aprēķini

t-tests ar iebūvēto funkciju:

``` {r}
res <- t.test(change,alternative="g",conf.level=0.95); res
```

t-testa rezultāts, kritiskā vērtība c, p-vērtība.

``` {r}
res$statistic
alpha <- 0.025
cutoff <- qt(1-alpha,n-1); cutoff
res$p.value
```

Kritiskais apgabals: c > t; pieņemšanas apbgabals: c < t

### d) t-testa grafisks attēlojums


``` {r}
xax <- seq(-3,3,0.1)
plot(xax,dt(xax,n-1),type="l")
abline(v=res$statistic,col="red")
abline(h=0,lty=2)
abline(v=cutoff,col="green")
```

### e) Secinājumi - hipotēzi pieņem vai noraida?

``` {r}
conclusion <- (res$p.value < 0.05)
conclusion
```

### f) Vai var izmantot Wilkoksona testu? Vai p-vērtība stipri atšķiras?

Testu izmantot var, palīdz fakts, ka dati doti arī pa pāriem. p-vērtība ir nedaudz sliktāka - ap 3% nevis ~1% kā t-testam.


``` {r}
wilcox.test(before,after,alternative="l",paired=T,exact=F)
```


\newpage

## 6. uzdevums

### a) Datu ielasīšana un apraksts.

Datu ielasīšana no faila. Dati sastāv no trīs kolonnām - urbšanas dziļumiem, vidējā urbšanas laika līdz katram dziļumam sausā režīmā, vidējā urbšanas laika līdz katram dziļumam slapjā režīmā. Dati ievākti sešos urbumos.


``` {r, message = FALSE}
df <- read.csv('cleaned.csv')
attach(df)
str(df)
summary(df)
```

Q: Kāpēc svarīgi salīdzināt urbšanas ilgumu atkarībā no režīma?

A: Pastāv iespēja, ka var ātrāk veikt urbumus sausajā režīmā.

### b) Punktu grafiks urbšanas laikiem un dziļumam

Bibliotēkas:

``` {r, message=FALSE}
require(ggplot2)
require(gridExtra)
```

Grafiku konstruēšana:

``` {r}
ap <- ggplot(data=df,aes(x=Depth, y=Wet)) + geom_point()   
bp <- ggplot(data=df,aes(x=Depth, y=Dry)) + geom_point()
grid.arrange(ap,bp,ncol=2)
```

Q: Vai urbšanas ilgums ir atkarīgs no urbuma dziļuma?

A: Pie nelieliem dziļumiem, izskatās, ka nē - droši vien dominē citi faktori. Pie lielākiem dziļumiem - izskatās, ka jā.

Q: Pie kāda dziļuma notiek pārmaiņa?

A: Pēc grafika spriežot, aptuveni 200m.

Q: Kādi varētu būt iemesli?

A: Kā viena no iespējām grāmatā tiek minēta cietāka klints lielākos dziļumos. Cita iespēja varētu būt fakts, ka dziļākā urbumā lielāku daļu no kopējā urbšanas ilguma sastāda tīri mehāniskais urbšanas process, nevis dažādi nesaistīti kavēkļi.

### c) Kastu grafiks slapjai un sausai urbšanai

Aprakstošas statistikas:

``` {r, message=FALSE}
require(psych)
describe(Dry)
describe(Wet)
```

Kastu grafiks:

``` {r, message=FALSE}
require(reshape)
md <- melt(df[,2:3])
ggplot(data=md,aes(x=as.factor(variable),y=value)) + geom_boxplot()
```

Izmainīta funkcija QQ salīdzinājumam, QQ salīdzinājums

```{r, results=FALSE, message=FALSE}
compare_QQ <- function(d,v1,v2){
  x <- subset(d, variable==v1)$value
  y <- subset(d, variable==v2)$value
  sx <- sort(x)
  sy <- sort(y)
  lenx <- length(sx)
  leny <- length(sy)
  if (leny < lenx) sx <- approx(1L:lenx, sx, n = leny)$y
  if (leny > lenx) sy <- approx(1L:leny, sy, n = lenx)$y
  require(ggplot2)
  g = ggplot() + geom_point(aes(x=sx, y=sy))+
    geom_abline(intercept =0, slope = 1)+
    labs(title="QQ compare",x=v1,y=v2)
  g
}

compare_QQ(melt(df[,2:3]),"Dry","Wet")
```

Q: Vai dispersijas var būt vienādas?

A: Dati izskatās diezgan līdzīgi tikai nedaudz nobīdīti mazāko vērtību apgabalā, taču izskatās, ka parādās lielākas atšķirības pie lielākām vērtībām. Vizuāli dispersiju nav viegli novērtēt.

### d) Salīdzinājums

Pieņemot vienādas dispersijas:

``` {r}
t.test(Dry,Wet,alternative="two.sided",var.equal=T,conf.level=0.95)
```

Pieņemot dažādas dispersijas:

``` {r}
t.test(Dry,Wet,alternative="two.sided",var.equal=F,conf.level=0.95)
```

Dispersiju vienādības pārbaude:

``` {r}
dv <- var.test(Dry,Wet,conf.level=0.99); dv
conf <- 0.05
dv$p.value
dv$estimate
(dv$p.value < conf)
```

Stingri runājot, dispersiju vienādības hipotēze netiek noraidīta, taču tā ir uz robežas.

Salīdzinājums "plakanajā" reģionā, 0-200ft, vispirms nosakot, vai dispersijas ir dažādas:

``` {r}
flat <- subset(df,Depth<200)
dv <- var.test(flat$Dry,flat$Wet,conf.level=0.95); dv
(dv$p.value < conf)
```

Tā kā dispersijas diezgan pārliecinoši ir vienādas, tālāku pārbaudi veic, pieņemot vienādu dispersiju:

``` {r}
res <- t.test(flat$Dry,flat$Wet,alternative="two.sided",var.equal=T,conf.level=0.95)
```

### e) Vai noraida hipotēzi H0: mu(Wet) = mu(Dry) ?

```{r}
!(res$conf.int[1] < 0 & res$conf.int[2] > 0)
```
